
# ğŸ“–ä½¿ç”¨æ•™ç¨‹
[![README](https://img.shields.io/badge/_è¿”å›README-æ–‡æ¡£-blue?style=flat&logo=readme)](../README.md)

## 1. æ•°æ®é‡‡é›†
å…ˆæŸ¥çœ‹å’Œç¡®ä¿æœºæ¢°è‡‚ä¸ç›¸æœºçš„è¿æ¥æ˜¯å¦æ­£å¸¸ä»¥åŠæŸ¥çœ‹å¯¹åº”çš„ç«¯å£ï¼Œå¯åœ¨ç»ˆç«¯è¾“å…¥ä»¥ä¸‹æŒ‡ä»¤ï¼š
```
conda activate lerobot # éœ€è¦å…ˆæ¿€æ´»lerobotç¯å¢ƒ
lerobot-find-cameras opencv # æŸ¥çœ‹æ‘„åƒå¤´çš„æ¥å…¥ä¿¡æ¯
```
<img width="600" height="252" alt="2025-10-15 14-33-03 çš„å±å¹•æˆªå›¾" src="https://github.com/user-attachments/assets/522f2799-8589-4d62-95b6-35d4514d5b07" />

å…¶ä¸­â€œId: /dev/video0â€ä¿¡æ¯ä¸­videoåé¢çš„æ•°å­—å³ä¸ºè¯¥æ‘„åƒå¤´çš„ç¼–å·ï¼Œåé¢éœ€è¦ç”¨åˆ°ï¼
```
ls /dev/ttyACM* # æŸ¥çœ‹æœºæ¢°è‡‚çš„æ¥å…¥ç«¯å£
```
<img width="706" height="33" alt="2025-10-15 14-38-18 çš„å±å¹•æˆªå›¾" src="https://github.com/user-attachments/assets/c6bc9f88-d5d4-4e3e-967a-82c362e5fda5" />

å¯é€šè¿‡æ’æ‹”ç¡®å®šå…·ä½“ä¸»ä»å¯¹åº”çš„ç«¯å£ï¼Œæ³¨æ„ä¸è¦æåï¼
```
sudo chmod 666 /dev/ttyACM* # èµ‹äºˆç«¯å£æƒé™
```

ç„¶åè°ƒç”¨é‡‡é›†æ•°æ®çš„è„šæœ¬æ”¶é›†æ•°æ®ï¼Œè‹¥ä¹‹å‰æœªè¿›è¡Œæ ¡å‡†ä¼šå…ˆæç¤ºè¿›è¡Œæ ¡å‡†ï¼Œæ ¡å‡†æ–‡ä»¶ä¼šä¿å­˜åœ¨~/.cache/huggingface/lerobot/calibrationè·¯å¾„ä¸‹ï¼Œè‹¥æƒ³é‡æ–°æ ¡å‡†éœ€å…ˆåˆ é™¤æ”¹è·¯å¾„ä¸‹å­˜åœ¨çš„æ ¡å‡†æ–‡ä»¶
```
lerobot-record \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}, wrist: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30}}" \
    --teleop.type=so101_leader \
    --teleop.port=/dev/ttyACM1 \
    --teleop.id=my_awesome_leader_arm \
    --display_data=true \
    --dataset.repo_id=seeedstudio123/pen_and_cloth \
    --dataset.num_episodes=5 \
    --dataset.single_task="place the pens and eraser into the white bowl,then use the cloth to clean the table,finally place the cloth next to the white bowl" \
    --dataset.push_to_hub=false \
    --dataset.episode_time_s=40 \
    --dataset.reset_time_s=5 
```
å…¶ä¸­repo_idå¯ä»¥è‡ªå®šä¹‰ä¿®æ”¹ï¼Œpush_to_hub=falseï¼Œæœ€åæ•°æ®é›†ä¼šä¿å­˜åœ¨ä¸»ç›®å½•çš„~/.cache/huggingface/lerobotä¸‹ä¼šåˆ›å»ºä¸Šè¿°seeedstudio123/testæ–‡ä»¶å¤¹ï¼Œå¦‚æœè®°å½•è¿‡ç¨‹ä¸­æ–­ï¼Œå¯ä»¥é€šè¿‡é‡æ–°è¿è¡Œç›¸åŒçš„å‘½ä»¤å¹¶æ·»åŠ  --resume=true æ¥æ¢å¤è®°å½•
#### æ³¨æ„ï¼šlerobotåŸä»“åº“å†…çš„ä»£ç å¯¹æ•°æ®é›†çš„ä¿å­˜åšäº†æ–‡ä»¶å¤§å°çš„åˆ¤æ–­ï¼Œä¸€èˆ¬ä¼šæŠŠæ‰€æœ‰episodeæ•´åˆä¿å­˜åœ¨ä¸€ä¸ªæ–‡ä»¶é‡Œï¼Œæ‰€ä»¥ä¸ºäº†åç»­æ–¹ä¾¿æ•°æ®è½¬æ¢ï¼Œå»ºè®®å¯¹lerobot/src/lerobot/dataset/utils.pyæ–‡ä»¶è¿›è¡Œä»¥ä¸‹ä¿®æ”¹ï¼ï¼ï¼
<img width="564" height="75" alt="2025-10-15 15-07-45 çš„å±å¹•æˆªå›¾" src="https://github.com/user-attachments/assets/bda8dc5e-5c85-4cfd-8be1-bffced0e6c60" />

## 2. æ•°æ®è½¬æ¢
#### GR00Téœ€è¦å°†åŸå§‹çš„lerobotæ•°æ®æ–‡ä»¶æ·»åŠ ç›¸å…³é…ç½®æ–‡ä»¶æ‰å¯è®­ç»ƒï¼ˆå…·ä½“è§GR00Tå®˜ç½‘ä»‹ç»ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬è‡ªè¡Œç¼–å†™äº†ä¸€ä¸ªdataset_le2gr00t.pyæ¥è¿›è¡Œæ•°æ®è½¬æ¢æ“ä½œ,è¯¥ä»£ç å­˜æ”¾åœ¨/ISSAC-GR00T-LE/scripts/æ–‡ä»¶å¤¹ä¸‹
å…ˆå°†å½•åˆ¶çš„æ•°æ®é›†ç§»åŠ¨åˆ°/ISSAC-GR00T-LE/demo_dataç›®å½•ä¸‹ï¼Œç„¶åç»ˆç«¯cdåˆ°/ISSAC-GR00T-LEç›®å½•ä¸‹è¿è¡Œ
```
conda activate gr00t-server # æ¿€æ´»gr00t-serverè™šæ‹Ÿç¯å¢ƒ
python scripts/dataset_le2gr00t.py # è¿è¡Œè½¬æ¢è„šæœ¬ï¼Œæ ¹æ®æç¤ºé€‰æ‹©æ•°æ®é›†  
```
<img width="1132" height="321" alt="2025-10-15 15-35-06 çš„å±å¹•æˆªå›¾" src="https://github.com/user-attachments/assets/b3da6931-1404-42b9-a5c6-16ce6ede8ede" />

#### æ³¨æ„ï¼šè¿™é‡Œè„šæœ¬ä¼šåˆ›å»ºä¸€ä»½modality.jsonçš„æ–‡ä»¶ï¼Œè·Ÿæ‘„åƒå¤´é…ç½®æœ‰å…³ç³»ï¼ˆå…·ä½“è§GR00Tå®˜ç½‘ä»‹ç»ï¼‰ï¼Œè‹¥åœ¨å½•åˆ¶æ—¶æ”¹å˜äº†æ‘„åƒå¤´é…ç½®ï¼Œéœ€åœ¨è¯¥æ•°æ®è½¬æ¢è„šæœ¬é‡Œä¿®æ”¹ç›¸åº”çš„å†…å®¹ã€‚å»ºè®®å¦‚æœä½¿ç”¨ä¸¤ä¸ªæ‘„åƒå¤´çš„é…ç½®ï¼Œä¸è¦ä¿®æ”¹"front"å’Œâ€œwristâ€å­—æ®µï¼Œåªéœ€è‡ªè¡Œæ¸…æ¥šå“ªä¸ªå¯¹åº”å“ªä¸ªindex_or_pathå³å¯ã€‚

## 3. å¾®è°ƒè®­ç»ƒ
åœ¨gr00t-serverç¯å¢ƒä¸‹è¿è¡Œï¼š
```
python scripts/gr00t_finetune.py \
   --dataset-path ./demo_data/pen_and_cloth/ \
   --num-gpus 1 \
   --output-dir ./finetuned_models/pen_and_cloth  \
   --max-steps 20000 \
   --data-config so100_dualcam \
   --video-backend torchvision_av
```
è‹¥GPUæ˜¾å­˜è¾ƒå°ï¼Œå†»ç»“diffusionå¾®è°ƒ,æˆ–å‡å°--batch_size 16
```
python scripts/gr00t_finetune.py \
   --dataset-path ./demo_data/pen_and_cloth/ \
   --num-gpus 1 \
   --output-dir ./finetuned_models/pen_and_cloth \
   --max-steps 20000 \
   --data-config so100_dualcam \
   --video-backend torchvision_av \
   --no-tune_diffusion_model
```
## 4. å¼€ç¯è¯„ä¼°
åœ¨gr00t-serverç¯å¢ƒä¸‹è¿è¡Œï¼š
```
python scripts/eval_policy.py --plot \
   --embodiment_tag new_embodiment \
   --model_path ./finetuned_models/pen_and_cloth_df \
   --data_config so100_dualcam \
   --dataset_path ./demo_data/pen_and_cloth/ \
   --video_backend torchvision_av \
   --modality_keys single_arm gripper \
   --trajs=10
```
<img width="350" height="400" alt="2025-10-15 16-17-57 çš„å±å¹•æˆªå›¾" src="https://github.com/user-attachments/assets/ff112f42-5ffb-4f98-a00f-1e4c548f8511" />

## 5. çœŸæœºéƒ¨ç½²
åœ¨gr00t-serverç¯å¢ƒä¸‹è¿è¡Œï¼š
```
python scripts/inference_service.py --server \
    --model_path ./finetuned_models/pen_and_cloth_df \
    --embodiment-tag new_embodiment \
    --data-config so100_dualcam \
    --denoising-steps 4
```
ç„¶åæ–°å¼€ä¸€ä¸ªç»ˆç«¯ï¼Œåœ¨gr00t-clientç¯å¢ƒä¸‹è¿è¡Œï¼š
```
python examples/SO-100/eval_lerobot.py \
    --robot.type=so101_follower \
    --robot.port=/dev/ttyACM0 \
    --robot.id=my_awesome_follower_arm \
    --robot.cameras="{ wrist: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30}, front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}}" \
    --policy_host=127.0.0.1 \
    --lang_instruction="place the pens and eraser into the white bowl,then use the cloth to clean the table,finally place the cloth next to the white bowl."
```

